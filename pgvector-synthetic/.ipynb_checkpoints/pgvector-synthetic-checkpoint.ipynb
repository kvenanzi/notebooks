{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbbd84d6-fc7b-44bd-95bc-e3d9278496bd",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "* PostgreSQL reachable at localhost:5432 with a database named patient_db and credentials matching the connection cell (user=\"kevin\", password=\"password123\"). Install the pgvector extension in this database.\n",
    "* Python environment capable of installing packages listed below (the notebook relies on pip inside the runtime).\n",
    "* Data files ./patients.csv and ./allergies.csv present relative to the notebook.\n",
    "* Ollama running locally on the default port 11434 with the phi4-mini embedding model pulled and ready (ollama pull phi4-mini)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d45dac-2f8f-443a-a931-adb006c70589",
   "metadata": {},
   "source": [
    "# 1. Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5528b6a6-de86-4902-b6d1-e9a48ce921f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install psycopg2-binary pandas numpy matplotlib plotly faker requests umap-learn tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee55fbb-9abf-4190-a296-8f90d6a26fc3",
   "metadata": {},
   "source": [
    "# 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fce2b4-318b-4ce7-a855-9adc383a7d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, requests\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5d7c53-03dc-47b6-9ebf-35e319b6645d",
   "metadata": {},
   "source": [
    "# 3. Connect to PostgreSQL with pgvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcbfbf6-db0e-4722-bc5a-e09f15589265",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "    dbname=\"patient_db\",\n",
    "    user=\"kevin\",\n",
    "    password=\"password123\",\n",
    "    host=\"localhost\",\n",
    "    port=6432\n",
    ")\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67033158-c8bd-4347-86b8-aabf3698b69d",
   "metadata": {},
   "source": [
    "# 4. Load CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463260e5-c89a-4e34-99e4-822b7a6872f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "patients_df = pd.read_csv(\"./data/patients.csv\")\n",
    "allergies_df = pd.read_csv(\"./data/allergies.csv\")\n",
    "\n",
    "print(\"Patients:\")\n",
    "display(patients_df.head())\n",
    "\n",
    "print(\"Allergies:\")\n",
    "display(allergies_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2cef44-5ff5-4bb0-90da-deb89853c1bd",
   "metadata": {},
   "source": [
    "# 5. Create normalized tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f21eae-a466-493e-a39b-56523b962caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.rollback()\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "DROP TABLE IF EXISTS allergies CASCADE;\n",
    "DROP TABLE IF EXISTS patients CASCADE;\n",
    "\n",
    "CREATE TABLE patients (\n",
    "    patient_id TEXT PRIMARY KEY,\n",
    "    vista_id TEXT,\n",
    "    mrn TEXT,\n",
    "    first_name TEXT,\n",
    "    last_name TEXT,\n",
    "    middle_name TEXT,\n",
    "    gender TEXT,\n",
    "    birthdate TEXT,          -- changed from DATE to TEXT for flexibility\n",
    "    age INT,\n",
    "    race TEXT,\n",
    "    ethnicity TEXT,\n",
    "    address TEXT,\n",
    "    city TEXT,\n",
    "    state TEXT,\n",
    "    zip TEXT,\n",
    "    country TEXT,\n",
    "    phone TEXT,\n",
    "    email TEXT,\n",
    "    marital_status TEXT,\n",
    "    language TEXT,\n",
    "    insurance TEXT,\n",
    "    ssn TEXT,\n",
    "    smoking_status TEXT,\n",
    "    alcohol_use TEXT,\n",
    "    education TEXT,\n",
    "    employment_status TEXT,\n",
    "    income TEXT,\n",
    "    housing_status TEXT,\n",
    "    sdoh_risk_score FLOAT,\n",
    "    sdoh_risk_factors TEXT,\n",
    "    community_deprivation_index FLOAT,\n",
    "    access_to_care_score FLOAT,\n",
    "    transportation_access TEXT,\n",
    "    language_access_barrier TEXT,\n",
    "    social_support_score FLOAT,\n",
    "    sdoh_care_gaps TEXT,\n",
    "    genetic_risk_score FLOAT,\n",
    "    genetic_markers TEXT,\n",
    "    precision_markers TEXT,\n",
    "    comorbidity_profile TEXT,\n",
    "    care_plan_total INT,\n",
    "    care_plan_completed INT,\n",
    "    care_plan_overdue INT,\n",
    "    care_plan_scheduled INT,\n",
    "    deceased BOOLEAN,\n",
    "    death_date TEXT,         -- also TEXT now\n",
    "    death_primary_cause TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE allergies (\n",
    "    allergy_id TEXT PRIMARY KEY,\n",
    "    patient_id TEXT,\n",
    "    substance TEXT,\n",
    "    category TEXT,\n",
    "    reaction TEXT,\n",
    "    reaction_code TEXT,\n",
    "    reaction_system TEXT,\n",
    "    severity TEXT,\n",
    "    severity_code TEXT,\n",
    "    severity_system TEXT,\n",
    "    rxnorm_code TEXT,\n",
    "    unii_code TEXT,\n",
    "    snomed_code TEXT,\n",
    "    risk_level TEXT,\n",
    "    registry_source TEXT,\n",
    "    recorded_date TEXT,\n",
    "    followup_summary TEXT\n",
    ");\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "print(\"âœ… Tables recreated successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4290b02-8a37-4d3c-9ebe-83d0ea6759b5",
   "metadata": {},
   "source": [
    "# 6. Bulk-insert dataframes into Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2af22f-9ccc-4f71-9f4e-59db3803307d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "def copy_dataframe(df, table_name):\n",
    "    # Make sure nulls are proper SQL NULLs\n",
    "    df = df.replace({np.nan: None})\n",
    "\n",
    "    # Write DataFrame to CSV buffer with quoting handled by pandas\n",
    "    buffer = StringIO()\n",
    "    df.to_csv(\n",
    "        buffer,\n",
    "        index=False,\n",
    "        header=False,\n",
    "        sep=\",\",\n",
    "        quoting=1,  # csv.QUOTE_ALL\n",
    "        escapechar=\"\\\\\"\n",
    "    )\n",
    "    buffer.seek(0)\n",
    "\n",
    "    try:\n",
    "        cur.copy_expert(\n",
    "            sql=f\"COPY {table_name} FROM STDIN WITH (FORMAT CSV, HEADER FALSE, DELIMITER ',', QUOTE '\\\"', ESCAPE '\\\\')\",\n",
    "            file=buffer\n",
    "        )\n",
    "        conn.commit()\n",
    "        print(f\"âœ… Loaded {len(df)} rows into {table_name}\")\n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        print(f\"âŒ Error loading {table_name}: {e}\")\n",
    "\n",
    "# --- Clean and normalize the patients dataframe ---\n",
    "patients_df = patients_df.replace({np.nan: None})  # Convert NaN to None\n",
    "\n",
    "# Normalize date columns: replace blanks with None, cast to str for CSV writing\n",
    "for col in [\"birthdate\", \"death_date\"]:\n",
    "    patients_df[col] = patients_df[col].apply(lambda x: None if pd.isna(x) or x == \"\" else str(x))\n",
    "\n",
    "# --- Filter allergies to valid patient_ids ---\n",
    "allergies_df = allergies_df[allergies_df[\"patient_id\"].isin(patients_df[\"patient_id\"])].copy()\n",
    "\n",
    "# Confirm how many rows remain\n",
    "print(f\"Patients: {len(patients_df)} | Allergies (filtered): {len(allergies_df)}\")\n",
    "# Run it\n",
    "copy_dataframe(patients_df, \"patients\")\n",
    "copy_dataframe(allergies_df, \"allergies\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfffc16-db86-46aa-9aa7-96c3edde54f4",
   "metadata": {},
   "source": [
    "# 7. Join data into patient â€œcontextâ€ paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14953bbc-90be-4c46-a9ab-a1f4eb7ef9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 7 (replace completely) ---\n",
    "query = \"\"\"\n",
    "WITH agg AS (\n",
    "  SELECT\n",
    "    p.patient_id,\n",
    "    p.first_name, p.last_name, p.gender, p.age, p.race, p.ethnicity,\n",
    "    p.sdoh_risk_score,\n",
    "    CASE\n",
    "      WHEN p.sdoh_risk_score >= 0.70 THEN 'HIGH'\n",
    "      WHEN p.sdoh_risk_score >= 0.40 THEN 'MEDIUM'\n",
    "      ELSE 'LOW'\n",
    "    END AS sdoh_bucket,\n",
    "    COALESCE(p.insurance, 'Unknown') AS insurance,\n",
    "    COALESCE(p.smoking_status, 'Unknown') AS smoking_status,\n",
    "    COALESCE(p.deceased, FALSE) AS deceased,\n",
    "    NULLIF(p.death_date, '') AS death_date_raw,\n",
    "    COUNT(a.allergy_id) AS allergy_count,\n",
    "    MAX(CASE WHEN LOWER(COALESCE(a.severity,'')) IN ('severe','high','life-threatening') THEN 1 ELSE 0 END) AS any_severe_allergy,\n",
    "    STRING_AGG(a.substance || ' (' || COALESCE(a.severity,'unknown') || ')', '; ' ORDER BY a.substance) AS allergy_list\n",
    "  FROM patients p\n",
    "  LEFT JOIN allergies a ON p.patient_id = a.patient_id\n",
    "  GROUP BY p.patient_id, p.first_name, p.last_name, p.gender, p.age, p.race, p.ethnicity,\n",
    "           p.sdoh_risk_score, insurance, smoking_status, deceased, p.death_date\n",
    ")\n",
    "SELECT\n",
    "  patient_id,\n",
    "  CONCAT(\n",
    "    'Patient: ', first_name, ' ', last_name, '. ',\n",
    "    'Gender: ', COALESCE(gender,'unknown'), '; Age: ', COALESCE(age::text,'unknown'), '. ',\n",
    "    'Race: ', COALESCE(race,'unspecified'), '; Ethnicity: ', COALESCE(ethnicity,'unspecified'), '. ',\n",
    "    'SDOH: ', sdoh_bucket, ' (', COALESCE(sdoh_risk_score::text,'n/a'), '). ',\n",
    "    'Insurance: ', insurance, '; Smoking: ', smoking_status, '. ',\n",
    "    'Deceased: ', CASE WHEN deceased THEN 'yes' ELSE 'no' END,\n",
    "    CASE WHEN deceased AND death_date_raw IS NOT NULL THEN CONCAT(' (death_date=', death_date_raw, ')') ELSE '' END, '. ',\n",
    "    'Allergies: ', COALESCE(allergy_list,'none'), '. ',\n",
    "    'Allergy_count: ', allergy_count::text, '; Any_severe_allergy: ', any_severe_allergy::text, '.'\n",
    "  ) AS context_text\n",
    "FROM agg;\n",
    "\"\"\"\n",
    "\n",
    "df_context = pd.read_sql(query, conn)\n",
    "print(f\"âœ… Created {len(df_context)} patient context records with labeled facts\")\n",
    "df_context.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42df8cf5-8efa-4796-9a51-002f27a0c500",
   "metadata": {},
   "source": [
    "# 8. Local embedding function using Ollama Ï†4-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39a2538-b88e-465b-9bdf-39ae7e024bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_ollama_embedding(text, model=\"phi4-mini\"):\n",
    "    url = \"http://localhost:11434/api/embeddings\"\n",
    "    response = requests.post(url, json={\"model\": model, \"prompt\": text})\n",
    "    response.raise_for_status()\n",
    "    return response.json()[\"embedding\"]\n",
    "\n",
    "# Quick check\n",
    "test_emb = get_ollama_embedding(\"test patient embedding\")\n",
    "print(\"âœ… Embedding length:\", len(test_emb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946a191e-9457-4dc6-a84a-6ec02e8798ec",
   "metadata": {},
   "source": [
    "# 9: Create and fill patient_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e0d78c-7b09-4bda-9cf8-ea995727dd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cur.execute(\"DROP TABLE IF EXISTS patient_embeddings;\")\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE patient_embeddings (\n",
    "  patient_id TEXT PRIMARY KEY,\n",
    "  context_text TEXT,\n",
    "  embedding VECTOR(3072)\n",
    ");\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "\n",
    "for _, row in df_context.iterrows():\n",
    "    emb = get_ollama_embedding(row.context_text)\n",
    "    cur.execute(\n",
    "        \"INSERT INTO patient_embeddings (patient_id, context_text, embedding) VALUES (%s, %s, %s)\",\n",
    "        (row.patient_id, row.context_text, emb)\n",
    "    )\n",
    "conn.commit()\n",
    "print(\"âœ… Re-embedded patients with enriched context\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074e0d46-3cff-4680-af71-6149e7ba7765",
   "metadata": {},
   "source": [
    "# 10. Train UMAP reducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3447fb72-ef70-446c-acb7-c4ae39511c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import umap\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "\n",
    "cur.execute(\"SELECT patient_id, embedding FROM patient_embeddings;\")\n",
    "rows = cur.fetchall()\n",
    "\n",
    "embeddings = np.vstack([\n",
    "    np.array(ast.literal_eval(r[1]), dtype=np.float32) if isinstance(r[1], str) else np.array(r[1], dtype=np.float32)\n",
    "    for r in rows\n",
    "])\n",
    "patient_ids = [r[0] for r in rows]\n",
    "\n",
    "reducer = umap.UMAP(n_neighbors=5, min_dist=0.3, metric=\"cosine\", random_state=42)\n",
    "embedding_2d = reducer.fit_transform(embeddings)\n",
    "\n",
    "print(f\"âœ… UMAP trained on {len(patient_ids)} patient embeddings.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b6b8da-a0c2-4776-a279-78102a53f2d1",
   "metadata": {},
   "source": [
    "# 11. Semantic search query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf224d0-8f65-4d23-af87-916d4f22f6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = \"patients allergic to penicillin with high sdoh risk\"\n",
    "query_emb = get_ollama_embedding(query_text)\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT p.patient_id,\n",
    "       p.context_text,\n",
    "       1 - (p.embedding <=> %s::vector) AS similarity\n",
    "FROM patient_embeddings p\n",
    "ORDER BY similarity DESC\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "\n",
    "cur.execute(sql, (query_emb,))\n",
    "results = cur.fetchall()\n",
    "\n",
    "pd.DataFrame(results, columns=[\"patient_id\", \"context_text\", \"similarity\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b34be92-714f-4e31-8b8a-75251b4c68dc",
   "metadata": {},
   "source": [
    "# 12. Visualization (Matplotlib + Plotly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029cad23-2f0a-4c8f-8065-ca728f536393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 12: Visualize patient embeddings with optional query overlay ---\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(embedding_2d[:,0], embedding_2d[:,1], s=40, alpha=0.8)\n",
    "plt.title(\"Patient Embedding Clusters (Ï†4-mini)\")\n",
    "plt.xlabel(\"UMAP-1\")\n",
    "plt.ylabel(\"UMAP-2\")\n",
    "plt.show()\n",
    "\n",
    "# Optional: Interactive hover view\n",
    "df_plot = pd.DataFrame({\n",
    "    \"x\": embedding_2d[:,0],\n",
    "    \"y\": embedding_2d[:,1],\n",
    "    \"patient_id\": patient_ids,\n",
    "    \"context_text\": [r[1] for r in rows]\n",
    "})\n",
    "\n",
    "fig = px.scatter(\n",
    "    df_plot,\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    hover_data={\"patient_id\": True, \"context_text\": True},\n",
    "    title=\"Interactive Semantic Map of Patients\",\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "fig.update_traces(marker=dict(size=10, opacity=0.8))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65658a80-27a9-45a7-88aa-6c74f20df8da",
   "metadata": {},
   "source": [
    "# 12. Add NLP Semantic Search for Patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6907f219-9182-46ac-b8bf-8e9a4f930050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def embed_query_ollama(text, model=\"phi4-mini\"):\n",
    "    emb = get_ollama_embedding(text, model=model)\n",
    "    return np.array(emb, dtype=np.float32)\n",
    "    \n",
    "def semantic_search_fused(query_text, top_k=5):\n",
    "    # Parse rule-based filters\n",
    "    filters = parse_filters(query_text)\n",
    "    candidate_ids = candidate_ids_from_filters(filters)\n",
    "\n",
    "    if not candidate_ids:\n",
    "        cur.execute(\"SELECT patient_id, embedding FROM patient_embeddings;\")\n",
    "    else:\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT patient_id, embedding\n",
    "            FROM patient_embeddings\n",
    "            WHERE patient_id = ANY(%s);\n",
    "        \"\"\", (candidate_ids,))\n",
    "    rows = cur.fetchall()\n",
    "\n",
    "    if not rows:\n",
    "        print(\"No candidates match the prefilters.\")\n",
    "        return None, pd.DataFrame()\n",
    "\n",
    "    q_emb = embed_query_ollama(query_text).reshape(1, -1)\n",
    "\n",
    "    ids, mats = [], []\n",
    "    for pid, emb in rows:\n",
    "        if isinstance(emb, str):\n",
    "            emb = json.loads(emb)\n",
    "        mats.append(np.array(emb, dtype=np.float32))\n",
    "        ids.append(pid)\n",
    "    E = np.vstack(mats)\n",
    "\n",
    "    sims = cosine_similarity(q_emb, E)[0]\n",
    "    order = np.argsort(-sims)[:top_k]\n",
    "    top = [(ids[i], float(sims[i])) for i in order]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for pid, score in top:\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT first_name, last_name, gender, age, race, ethnicity,\n",
    "                   sdoh_risk_score, insurance, smoking_status, deceased, death_date\n",
    "            FROM patients WHERE patient_id = %s;\n",
    "        \"\"\", (pid,))\n",
    "        p = cur.fetchone()\n",
    "\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT substance, severity, reaction\n",
    "            FROM allergies WHERE patient_id = %s\n",
    "            ORDER BY severity DESC NULLS LAST, substance\n",
    "            LIMIT 3;\n",
    "        \"\"\", (pid,))\n",
    "        alls = cur.fetchall()\n",
    "        allergy_summary = \"; \".join([f\"{a[0]} ({a[1] or 'unknown'})\" for a in alls]) if alls else \"None\"\n",
    "\n",
    "        sdoh_bucket = \"HIGH\" if (p[6] and p[6] >= 0.70) else (\"MEDIUM\" if (p[6] and p[6] >= 0.40) else \"LOW\")\n",
    "\n",
    "        # --- EXPLANATION SECTION ---\n",
    "        explanations = []\n",
    "        if filters[\"gender\"]:\n",
    "            explanations.append(f\"gender={p[2]} {'âœ…' if p[2] and p[2].lower()==filters['gender'] else 'âŒ'}\")\n",
    "        if filters[\"sdoh_bucket\"]:\n",
    "            explanations.append(f\"SDOH={sdoh_bucket} {'âœ…' if sdoh_bucket==filters['sdoh_bucket'] else 'âŒ'}\")\n",
    "        if filters[\"deceased\"] is not None:\n",
    "            explanations.append(f\"deceased={p[9]} {'âœ…' if bool(p[9])==filters['deceased'] else 'âŒ'}\")\n",
    "        if filters[\"recent_days\"]:\n",
    "            explanations.append(f\"recent_check={filters['recent_days']}d window\")\n",
    "        explanation = \"; \".join(explanations) if explanations else \"No explicit filter matches\"\n",
    "\n",
    "        results.append({\n",
    "            \"Patient ID\": pid,\n",
    "            \"Name\": f\"{p[0]} {p[1]}\",\n",
    "            \"Gender\": p[2],\n",
    "            \"Age\": p[3],\n",
    "            \"SDOH\": f\"{sdoh_bucket} ({p[6]})\",\n",
    "            \"Insurance\": p[7],\n",
    "            \"Smoking\": p[8],\n",
    "            \"Deceased\": p[9],\n",
    "            \"Death Date\": p[10],\n",
    "            \"Allergies (sample)\": allergy_summary,\n",
    "            \"Similarity\": round(score, 3),\n",
    "            \"Filter Match Summary\": explanation\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "\n",
    "    print(f\"\\nðŸ”Ž Query: {query_text}\")\n",
    "    print(tabulate(df, headers='keys', tablefmt='fancy_grid', showindex=False))\n",
    "\n",
    "    return q_emb, df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737e9142-18af-49ac-8171-2701022ba9ea",
   "metadata": {},
   "source": [
    "# 13. Filtering + fused semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974ddb12-527f-46aa-b517-d20e83bca2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def parse_filters(query_text):\n",
    "    q = query_text.lower()\n",
    "\n",
    "    filters = {\n",
    "        \"gender\": None,\n",
    "        \"sdoh_bucket\": None,\n",
    "        \"deceased\": None,\n",
    "        \"recent_days\": None\n",
    "    }\n",
    "\n",
    "    if \"female\" in q: filters[\"gender\"] = \"female\"\n",
    "    if \"male\" in q and \"female\" not in q: filters[\"gender\"] = \"male\"\n",
    "\n",
    "    if \"high sdoh\" in q or \"high social risk\" in q:   filters[\"sdoh_bucket\"] = \"HIGH\"\n",
    "    elif \"low sdoh\" in q or \"low social risk\" in q:   filters[\"sdoh_bucket\"] = \"LOW\"\n",
    "    elif \"medium sdoh\" in q or \"medium social risk\" in q: filters[\"sdoh_bucket\"] = \"MEDIUM\"\n",
    "\n",
    "    if \"deceased\" in q or \"death\" in q:\n",
    "        filters[\"deceased\"] = True\n",
    "        if \"recent\" in q or \"recently\" in q:\n",
    "            filters[\"recent_days\"] = 180  # tweak as needed\n",
    "\n",
    "    return filters\n",
    "def candidate_ids_from_filters(filters):\n",
    "    clauses, params = [], []\n",
    "\n",
    "    if filters[\"gender\"]:\n",
    "        clauses.append(\"LOWER(gender) = %s\")\n",
    "        params.append(filters[\"gender\"])\n",
    "\n",
    "    if filters[\"sdoh_bucket\"]:\n",
    "        clauses.append(\"\"\"\n",
    "        CASE\n",
    "          WHEN sdoh_risk_score >= 0.70 THEN 'HIGH'\n",
    "          WHEN sdoh_risk_score >= 0.40 THEN 'MEDIUM'\n",
    "          ELSE 'LOW'\n",
    "        END = %s\n",
    "        \"\"\")\n",
    "        params.append(filters[\"sdoh_bucket\"])\n",
    "\n",
    "    if filters[\"deceased\"] is True and filters[\"recent_days\"]:\n",
    "        days = int(filters[\"recent_days\"])\n",
    "        clauses.append(f\"\"\"\n",
    "          COALESCE(deceased, FALSE) = TRUE\n",
    "          AND NULLIF(death_date,'') IS NOT NULL\n",
    "          AND death_date ~ '^[0-9]{{4}}-[0-9]{{2}}-[0-9]{{2}}$'\n",
    "          AND TO_DATE(death_date, 'YYYY-MM-DD') >= (CURRENT_DATE - INTERVAL '{days} days')\n",
    "        \"\"\")\n",
    "    \n",
    "    elif filters[\"deceased\"] is True:\n",
    "        clauses.append(\"COALESCE(deceased, FALSE) = TRUE\")\n",
    "\n",
    "    where_sql = (\"WHERE \" + \" AND \".join(clauses)) if clauses else \"\"\n",
    "    sql = f\"SELECT patient_id FROM patients {where_sql};\"\n",
    "    cur.execute(sql, params)\n",
    "    return [r[0] for r in cur.fetchall()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449cb275-e536-4938-8186-60da88ea0469",
   "metadata": {},
   "source": [
    "# Run queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e36b93-81ed-47bc-b864-87dd9ac610f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_emb, df_results = semantic_search_fused(\"patients experiencing headaches\", top_k=5)\n",
    "\n",
    "semantic_search_fused(\"recently deceased patient with respiratory reaction and low income\", top_k=5)\n",
    "\n",
    "semantic_search_fused(\"female patient deceased recently with severe drug allergy\", top_k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62359aa-fa31-477f-8615-d1eb3d755019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 13: Project query embedding into same UMAP ---\n",
    "q_emb = np.array(q_emb, dtype=np.float32).reshape(1, -1)\n",
    "q_emb_2d = reducer.transform(q_emb)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(embedding_2d[:,0], embedding_2d[:,1], alpha=0.3, label='Patients')\n",
    "plt.scatter(q_emb_2d[:,0], q_emb_2d[:,1], color='red', s=120, label='Query')\n",
    "plt.legend()\n",
    "plt.title(\"Query Position in Patient Semantic Space\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12833126-1b7b-4dcd-adc6-da6dbbb00320",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
