{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbbd84d6-fc7b-44bd-95bc-e3d9278496bd",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "* PostgreSQL reachable at localhost:5432 with a database named patient_db and credentials matching the connection cell (user=\"kevin\", password=\"password123\"). Install the pgvector extension in this database.\n",
    "* Python environment capable of installing packages listed below (the notebook relies on pip inside the runtime).\n",
    "* Data files ./patients.csv and ./allergies.csv present relative to the notebook.\n",
    "* Ollama running locally on the default port 11434 with the phi4-mini embedding model pulled and ready (ollama pull phi4-mini)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d45dac-2f8f-443a-a931-adb006c70589",
   "metadata": {},
   "source": [
    "# 1. Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5528b6a6-de86-4902-b6d1-e9a48ce921f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in /home/kevin/anaconda3/envs/lab/lib/python3.12/site-packages (2.9.11)\n",
      "Requirement already satisfied: pandas in /home/kevin/anaconda3/envs/lab/lib/python3.12/site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy in /home/kevin/anaconda3/envs/lab/lib/python3.12/site-packages (2.3.3)\n",
      "Requirement already satisfied: matplotlib in /home/kevin/anaconda3/envs/lab/lib/python3.12/site-packages (3.10.6)\n",
      "Requirement already satisfied: plotly in /home/kevin/anaconda3/envs/lab/lib/python3.12/site-packages (6.3.1)\n",
      "Requirement already satisfied: faker in /home/kevin/anaconda3/envs/lab/lib/python3.12/site-packages (37.12.0)\n",
      "Requirement already satisfied: requests in /home/kevin/anaconda3/envs/lab/lib/python3.12/site-packages (2.32.5)\n",
      "Requirement already satisfied: umap-learn in /home/kevin/anaconda3/envs/lab/lib/python3.12/site-packages (0.5.9.post2)\n",
      "Requirement already satisfied: tabulate in /home/kevin/anaconda3/envs/lab/lib/python3.12/site-packages (0.9.0)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/kevin/anaconda3/envs/lab/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/kevin/anaconda3/envs/lab/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/kevin/anaconda3/envs/lab/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/kevin/anaconda3/envs/lab/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/kevin/anaconda3/envs/lab/lib/python3.12/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/kevin/anaconda3/envs/lab/lib/python3.12/site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/kevin/anaconda3/envs/lab/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/kevin/anaconda3/envs/lab/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/kevin/anaconda3/envs/lab/lib/python3.12/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/kevin/anaconda3/envs/lab/lib/python3.12/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /home/kevin/anaconda3/envs/lab/lib/python3.12/site-packages (from plotly) (2.10.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/kevin/anaconda3/envs/lab/lib/python3.12/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/kevin/anaconda3/envs/lab/lib/python3.12/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/kevin/anaconda3/envs/lab/lib/python3.12/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kevin/anaconda3/envs/lab/lib/python3.12/site-packages (from requests) (2025.8.3)\n",
      "Requirement already satisfied: scipy>=1.3.1 in /home/kevin/anaconda3/envs/lab/lib/python3.12/site-packages (from umap-learn) (1.16.3)\n",
      "Requirement already satisfied: scikit-learn>=1.6 in /home/kevin/anaconda3/envs/lab/lib/python3.12/site-packages (from umap-learn) (1.7.2)\n",
      "Requirement already satisfied: numba>=0.51.2 in /home/kevin/anaconda3/envs/lab/lib/python3.12/site-packages (from umap-learn) (0.62.1)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /home/kevin/anaconda3/envs/lab/lib/python3.12/site-packages (from umap-learn) (0.5.13)\n",
      "Requirement already satisfied: tqdm in /home/kevin/anaconda3/envs/lab/lib/python3.12/site-packages (from umap-learn) (4.67.1)\n",
      "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in /home/kevin/anaconda3/envs/lab/lib/python3.12/site-packages (from numba>=0.51.2->umap-learn) (0.45.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/kevin/anaconda3/envs/lab/lib/python3.12/site-packages (from pynndescent>=0.5->umap-learn) (1.5.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/kevin/anaconda3/envs/lab/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/kevin/anaconda3/envs/lab/lib/python3.12/site-packages (from scikit-learn>=1.6->umap-learn) (3.6.0)\n",
      "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2-binary pandas numpy matplotlib plotly faker requests umap-learn tabulate python-dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee55fbb-9abf-4190-a296-8f90d6a26fc3",
   "metadata": {},
   "source": [
    "# 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8fce2b4-318b-4ce7-a855-9adc383a7d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os, requests\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "import plotly.express as px\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5d7c53-03dc-47b6-9ebf-35e319b6645d",
   "metadata": {},
   "source": [
    "# 3. Connect to PostgreSQL with pgvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbcbfbf6-db0e-4722-bc5a-e09f15589265",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "    dbname=\"patient_db\",\n",
    "    user=\"kevin\",\n",
    "    password=\"password123\",\n",
    "    host=\"localhost\",\n",
    "    port=6432\n",
    ")\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67033158-c8bd-4347-86b8-aabf3698b69d",
   "metadata": {},
   "source": [
    "# 4. Load CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "463260e5-c89a-4e34-99e4-822b7a6872f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patients:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>vista_id</th>\n",
       "      <th>mrn</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>middle_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>birthdate</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>...</th>\n",
       "      <th>genetic_markers</th>\n",
       "      <th>precision_markers</th>\n",
       "      <th>comorbidity_profile</th>\n",
       "      <th>care_plan_total</th>\n",
       "      <th>care_plan_completed</th>\n",
       "      <th>care_plan_overdue</th>\n",
       "      <th>care_plan_scheduled</th>\n",
       "      <th>deceased</th>\n",
       "      <th>death_date</th>\n",
       "      <th>death_primary_cause</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a7896ff7-3cfb-4a4f-ae92-02f58d2d691e</td>\n",
       "      <td>1168769</td>\n",
       "      <td>MRN893749</td>\n",
       "      <td>Kari</td>\n",
       "      <td>Hutchinson</td>\n",
       "      <td>D</td>\n",
       "      <td>female</td>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>7</td>\n",
       "      <td>White</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c89b6067-c181-412f-be7f-5ee597961ad7</td>\n",
       "      <td>9206201</td>\n",
       "      <td>MRN955810</td>\n",
       "      <td>Joseph</td>\n",
       "      <td>Swanson</td>\n",
       "      <td>W</td>\n",
       "      <td>male</td>\n",
       "      <td>1935-11-22</td>\n",
       "      <td>90</td>\n",
       "      <td>White</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-10-30</td>\n",
       "      <td>Acute myocardial infarction, unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>748503cd-2632-4e29-8c06-558ea9d64548</td>\n",
       "      <td>8857864</td>\n",
       "      <td>MRN854471</td>\n",
       "      <td>Mark</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>B</td>\n",
       "      <td>other</td>\n",
       "      <td>1989-11-08</td>\n",
       "      <td>36</td>\n",
       "      <td>White</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7701558f-0d71-492b-ae3c-e9e93aa79b86</td>\n",
       "      <td>6727969</td>\n",
       "      <td>MRN501764</td>\n",
       "      <td>Tina</td>\n",
       "      <td>Castillo</td>\n",
       "      <td>A</td>\n",
       "      <td>male</td>\n",
       "      <td>1965-11-14</td>\n",
       "      <td>60</td>\n",
       "      <td>White</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"primary\": \"Hypertension\", \"associated\": \"Di...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2021-10-31</td>\n",
       "      <td>Intentional self-harm by unspecified means, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3d0a4feb-f79e-4624-9c33-c2eb1c90489e</td>\n",
       "      <td>9256242</td>\n",
       "      <td>MRN248802</td>\n",
       "      <td>Jason</td>\n",
       "      <td>Smith</td>\n",
       "      <td>K</td>\n",
       "      <td>male</td>\n",
       "      <td>2001-11-05</td>\n",
       "      <td>24</td>\n",
       "      <td>Asian</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             patient_id  vista_id        mrn first_name  \\\n",
       "0  a7896ff7-3cfb-4a4f-ae92-02f58d2d691e   1168769  MRN893749       Kari   \n",
       "1  c89b6067-c181-412f-be7f-5ee597961ad7   9206201  MRN955810     Joseph   \n",
       "2  748503cd-2632-4e29-8c06-558ea9d64548   8857864  MRN854471       Mark   \n",
       "3  7701558f-0d71-492b-ae3c-e9e93aa79b86   6727969  MRN501764       Tina   \n",
       "4  3d0a4feb-f79e-4624-9c33-c2eb1c90489e   9256242  MRN248802      Jason   \n",
       "\n",
       "    last_name middle_name  gender   birthdate  age   race  ...  \\\n",
       "0  Hutchinson           D  female  2018-11-01    7  White  ...   \n",
       "1     Swanson           W    male  1935-11-22   90  White  ...   \n",
       "2   Henderson           B   other  1989-11-08   36  White  ...   \n",
       "3    Castillo           A    male  1965-11-14   60  White  ...   \n",
       "4       Smith           K    male  2001-11-05   24  Asian  ...   \n",
       "\n",
       "  genetic_markers precision_markers  \\\n",
       "0              []                []   \n",
       "1              []                []   \n",
       "2              []                []   \n",
       "3              []                []   \n",
       "4              []                []   \n",
       "\n",
       "                                 comorbidity_profile care_plan_total  \\\n",
       "0                                                 []               0   \n",
       "1                                                 []               3   \n",
       "2                                                 []               0   \n",
       "3  [{\"primary\": \"Hypertension\", \"associated\": \"Di...               6   \n",
       "4                                                 []               0   \n",
       "\n",
       "   care_plan_completed care_plan_overdue care_plan_scheduled deceased  \\\n",
       "0                    0                 0                   0    False   \n",
       "1                    0                 3                   0     True   \n",
       "2                    0                 0                   0    False   \n",
       "3                    1                 5                   0     True   \n",
       "4                    0                 0                   0    False   \n",
       "\n",
       "   death_date                                death_primary_cause  \n",
       "0         NaN                                                NaN  \n",
       "1  2025-10-30           Acute myocardial infarction, unspecified  \n",
       "2         NaN                                                NaN  \n",
       "3  2021-10-31  Intentional self-harm by unspecified means, in...  \n",
       "4         NaN                                                NaN  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allergies:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>allergy_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>substance</th>\n",
       "      <th>category</th>\n",
       "      <th>reaction</th>\n",
       "      <th>reaction_code</th>\n",
       "      <th>reaction_system</th>\n",
       "      <th>severity</th>\n",
       "      <th>severity_code</th>\n",
       "      <th>severity_system</th>\n",
       "      <th>rxnorm_code</th>\n",
       "      <th>unii_code</th>\n",
       "      <th>snomed_code</th>\n",
       "      <th>risk_level</th>\n",
       "      <th>registry_source</th>\n",
       "      <th>recorded_date</th>\n",
       "      <th>followup_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d8141746-f50b-4636-ba63-e7df88496831</td>\n",
       "      <td>a7896ff7-3cfb-4a4f-ae92-02f58d2d691e</td>\n",
       "      <td>Acremonium Strictum 50 Mg/Ml Injectable Solution</td>\n",
       "      <td>environment</td>\n",
       "      <td>Angioedema</td>\n",
       "      <td>41291007</td>\n",
       "      <td>http://snomed.info/sct</td>\n",
       "      <td>mild</td>\n",
       "      <td>255604002</td>\n",
       "      <td>http://snomed.info/sct</td>\n",
       "      <td>905073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>standard</td>\n",
       "      <td>warehouse</td>\n",
       "      <td>2021-04-22</td>\n",
       "      <td>risk: standard | severity: mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>292baf74-fac6-4862-b3c8-720d1460ea3c</td>\n",
       "      <td>c89b6067-c181-412f-be7f-5ee597961ad7</td>\n",
       "      <td>Administration Of First Dose Of Vaccine Produc...</td>\n",
       "      <td>drug</td>\n",
       "      <td>Nausea</td>\n",
       "      <td>422587007</td>\n",
       "      <td>http://snomed.info/sct</td>\n",
       "      <td>mild</td>\n",
       "      <td>255604002</td>\n",
       "      <td>http://snomed.info/sct</td>\n",
       "      <td>416591003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>416591003.0</td>\n",
       "      <td>standard</td>\n",
       "      <td>warehouse</td>\n",
       "      <td>1956-12-14</td>\n",
       "      <td>risk: standard | severity: mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5cf42c32-c2ed-451c-ad42-da9c600a001f</td>\n",
       "      <td>c89b6067-c181-412f-be7f-5ee597961ad7</td>\n",
       "      <td>Buckwheat 100 Mg/Ml Injectable Solution</td>\n",
       "      <td>food</td>\n",
       "      <td>Nausea</td>\n",
       "      <td>422587007</td>\n",
       "      <td>http://snomed.info/sct</td>\n",
       "      <td>mild</td>\n",
       "      <td>255604002</td>\n",
       "      <td>http://snomed.info/sct</td>\n",
       "      <td>904800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>standard</td>\n",
       "      <td>warehouse</td>\n",
       "      <td>1969-09-19</td>\n",
       "      <td>risk: standard | severity: mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52d3a0b5-5a55-4a54-8dd2-4589ca069618</td>\n",
       "      <td>748503cd-2632-4e29-8c06-558ea9d64548</td>\n",
       "      <td>Banana 100 Mg/Ml Injectable Solution</td>\n",
       "      <td>food</td>\n",
       "      <td>Urticaria</td>\n",
       "      <td>126485001</td>\n",
       "      <td>http://snomed.info/sct</td>\n",
       "      <td>mild</td>\n",
       "      <td>255604002</td>\n",
       "      <td>http://snomed.info/sct</td>\n",
       "      <td>891833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>standard</td>\n",
       "      <td>warehouse</td>\n",
       "      <td>1995-11-08</td>\n",
       "      <td>risk: standard | severity: mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3a3027b9-8477-447b-971e-6dbd3fbdac0c</td>\n",
       "      <td>748503cd-2632-4e29-8c06-558ea9d64548</td>\n",
       "      <td>Bee Venom</td>\n",
       "      <td>insect</td>\n",
       "      <td>Wheezing</td>\n",
       "      <td>56018004</td>\n",
       "      <td>http://snomed.info/sct</td>\n",
       "      <td>moderate</td>\n",
       "      <td>6736007</td>\n",
       "      <td>http://snomed.info/sct</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>high</td>\n",
       "      <td>curated</td>\n",
       "      <td>1993-12-11</td>\n",
       "      <td>risk: high | severity: moderate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             allergy_id                            patient_id  \\\n",
       "0  d8141746-f50b-4636-ba63-e7df88496831  a7896ff7-3cfb-4a4f-ae92-02f58d2d691e   \n",
       "1  292baf74-fac6-4862-b3c8-720d1460ea3c  c89b6067-c181-412f-be7f-5ee597961ad7   \n",
       "2  5cf42c32-c2ed-451c-ad42-da9c600a001f  c89b6067-c181-412f-be7f-5ee597961ad7   \n",
       "3  52d3a0b5-5a55-4a54-8dd2-4589ca069618  748503cd-2632-4e29-8c06-558ea9d64548   \n",
       "4  3a3027b9-8477-447b-971e-6dbd3fbdac0c  748503cd-2632-4e29-8c06-558ea9d64548   \n",
       "\n",
       "                                           substance     category    reaction  \\\n",
       "0   Acremonium Strictum 50 Mg/Ml Injectable Solution  environment  Angioedema   \n",
       "1  Administration Of First Dose Of Vaccine Produc...         drug      Nausea   \n",
       "2            Buckwheat 100 Mg/Ml Injectable Solution         food      Nausea   \n",
       "3               Banana 100 Mg/Ml Injectable Solution         food   Urticaria   \n",
       "4                                          Bee Venom       insect    Wheezing   \n",
       "\n",
       "   reaction_code         reaction_system  severity  severity_code  \\\n",
       "0       41291007  http://snomed.info/sct      mild      255604002   \n",
       "1      422587007  http://snomed.info/sct      mild      255604002   \n",
       "2      422587007  http://snomed.info/sct      mild      255604002   \n",
       "3      126485001  http://snomed.info/sct      mild      255604002   \n",
       "4       56018004  http://snomed.info/sct  moderate        6736007   \n",
       "\n",
       "          severity_system rxnorm_code unii_code  snomed_code risk_level  \\\n",
       "0  http://snomed.info/sct      905073       NaN          NaN   standard   \n",
       "1  http://snomed.info/sct   416591003       NaN  416591003.0   standard   \n",
       "2  http://snomed.info/sct      904800       NaN          NaN   standard   \n",
       "3  http://snomed.info/sct      891833       NaN          NaN   standard   \n",
       "4  http://snomed.info/sct         NaN       NaN          NaN       high   \n",
       "\n",
       "  registry_source recorded_date                 followup_summary  \n",
       "0       warehouse    2021-04-22  risk: standard | severity: mild  \n",
       "1       warehouse    1956-12-14  risk: standard | severity: mild  \n",
       "2       warehouse    1969-09-19  risk: standard | severity: mild  \n",
       "3       warehouse    1995-11-08  risk: standard | severity: mild  \n",
       "4         curated    1993-12-11  risk: high | severity: moderate  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "patients_df = pd.read_csv(\"./data/patients.csv\")\n",
    "allergies_df = pd.read_csv(\"./data/allergies.csv\")\n",
    "\n",
    "print(\"Patients:\")\n",
    "display(patients_df.head())\n",
    "\n",
    "print(\"Allergies:\")\n",
    "display(allergies_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2cef44-5ff5-4bb0-90da-deb89853c1bd",
   "metadata": {},
   "source": [
    "# 5. Create normalized tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20f21eae-a466-493e-a39b-56523b962caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tables recreated successfully\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "DROP TABLE IF EXISTS allergies CASCADE;\n",
    "DROP TABLE IF EXISTS patients CASCADE;\n",
    "\n",
    "CREATE TABLE patients (\n",
    "    patient_id TEXT PRIMARY KEY,\n",
    "    vista_id TEXT,\n",
    "    mrn TEXT,\n",
    "    first_name TEXT,\n",
    "    last_name TEXT,\n",
    "    middle_name TEXT,\n",
    "    gender TEXT,\n",
    "    birthdate TEXT,          -- changed from DATE to TEXT for flexibility\n",
    "    age INT,\n",
    "    race TEXT,\n",
    "    ethnicity TEXT,\n",
    "    address TEXT,\n",
    "    city TEXT,\n",
    "    state TEXT,\n",
    "    zip TEXT,\n",
    "    country TEXT,\n",
    "    phone TEXT,\n",
    "    email TEXT,\n",
    "    marital_status TEXT,\n",
    "    language TEXT,\n",
    "    insurance TEXT,\n",
    "    ssn TEXT,\n",
    "    smoking_status TEXT,\n",
    "    alcohol_use TEXT,\n",
    "    education TEXT,\n",
    "    employment_status TEXT,\n",
    "    income TEXT,\n",
    "    housing_status TEXT,\n",
    "    sdoh_risk_score FLOAT,\n",
    "    sdoh_risk_factors TEXT,\n",
    "    community_deprivation_index FLOAT,\n",
    "    access_to_care_score FLOAT,\n",
    "    transportation_access TEXT,\n",
    "    language_access_barrier TEXT,\n",
    "    social_support_score FLOAT,\n",
    "    sdoh_care_gaps TEXT,\n",
    "    genetic_risk_score FLOAT,\n",
    "    genetic_markers TEXT,\n",
    "    precision_markers TEXT,\n",
    "    comorbidity_profile TEXT,\n",
    "    care_plan_total INT,\n",
    "    care_plan_completed INT,\n",
    "    care_plan_overdue INT,\n",
    "    care_plan_scheduled INT,\n",
    "    deceased BOOLEAN,\n",
    "    death_date TEXT,         -- also TEXT now\n",
    "    death_primary_cause TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE allergies (\n",
    "    allergy_id TEXT PRIMARY KEY,\n",
    "    patient_id TEXT,\n",
    "    substance TEXT,\n",
    "    category TEXT,\n",
    "    reaction TEXT,\n",
    "    reaction_code TEXT,\n",
    "    reaction_system TEXT,\n",
    "    severity TEXT,\n",
    "    severity_code TEXT,\n",
    "    severity_system TEXT,\n",
    "    rxnorm_code TEXT,\n",
    "    unii_code TEXT,\n",
    "    snomed_code TEXT,\n",
    "    risk_level TEXT,\n",
    "    registry_source TEXT,\n",
    "    recorded_date TEXT,\n",
    "    followup_summary TEXT\n",
    ");\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "print(\"‚úÖ Tables recreated successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4290b02-8a37-4d3c-9ebe-83d0ea6759b5",
   "metadata": {},
   "source": [
    "# 6. Bulk-insert dataframes into Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da2af22f-9ccc-4f71-9f4e-59db3803307d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patients: 1000 | Allergies (filtered): 1026\n",
      "‚úÖ Loaded 1000 rows into patients\n",
      "‚úÖ Loaded 1026 rows into allergies\n"
     ]
    }
   ],
   "source": [
    "from io import StringIO\n",
    "\n",
    "def copy_dataframe(df, table_name):\n",
    "    # Make sure nulls are proper SQL NULLs\n",
    "    df = df.replace({np.nan: None})\n",
    "\n",
    "    # Write DataFrame to CSV buffer with quoting handled by pandas\n",
    "    buffer = StringIO()\n",
    "    df.to_csv(\n",
    "        buffer,\n",
    "        index=False,\n",
    "        header=False,\n",
    "        sep=\",\",\n",
    "        quoting=1,  # csv.QUOTE_ALL\n",
    "        escapechar=\"\\\\\"\n",
    "    )\n",
    "    buffer.seek(0)\n",
    "\n",
    "    try:\n",
    "        cur.copy_expert(\n",
    "            sql=f\"COPY {table_name} FROM STDIN WITH (FORMAT CSV, HEADER FALSE, DELIMITER ',', QUOTE '\\\"', ESCAPE '\\\\')\",\n",
    "            file=buffer\n",
    "        )\n",
    "        conn.commit()\n",
    "        print(f\"‚úÖ Loaded {len(df)} rows into {table_name}\")\n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        print(f\"‚ùå Error loading {table_name}: {e}\")\n",
    "\n",
    "# --- Clean and normalize the patients dataframe ---\n",
    "patients_df = patients_df.replace({np.nan: None})  # Convert NaN to None\n",
    "\n",
    "# Normalize date columns: replace blanks with None, cast to str for CSV writing\n",
    "for col in [\"birthdate\", \"death_date\"]:\n",
    "    patients_df[col] = patients_df[col].apply(lambda x: None if pd.isna(x) or x == \"\" else str(x))\n",
    "\n",
    "# --- Filter allergies to valid patient_ids ---\n",
    "allergies_df = allergies_df[allergies_df[\"patient_id\"].isin(patients_df[\"patient_id\"])].copy()\n",
    "\n",
    "# Confirm how many rows remain\n",
    "print(f\"Patients: {len(patients_df)} | Allergies (filtered): {len(allergies_df)}\")\n",
    "# Run it\n",
    "copy_dataframe(patients_df, \"patients\")\n",
    "copy_dataframe(allergies_df, \"allergies\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfffc16-db86-46aa-9aa7-96c3edde54f4",
   "metadata": {},
   "source": [
    "# 7. Join data into patient ‚Äúcontext‚Äù paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14953bbc-90be-4c46-a9ab-a1f4eb7ef9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created 1000 patient context records with labeled facts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97067/1374959709.py:41: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_context = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>context_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>004b6780-7827-4030-a9e7-b7c9f44b2fab</td>\n",
       "      <td>Patient: John Weaver. Gender: female; Age: 54....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00840f4a-78ed-4b56-99d4-b3b375ccc277</td>\n",
       "      <td>Patient: Andrew Lopez. Gender: other; Age: 115...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             patient_id  \\\n",
       "0  004b6780-7827-4030-a9e7-b7c9f44b2fab   \n",
       "1  00840f4a-78ed-4b56-99d4-b3b375ccc277   \n",
       "\n",
       "                                        context_text  \n",
       "0  Patient: John Weaver. Gender: female; Age: 54....  \n",
       "1  Patient: Andrew Lopez. Gender: other; Age: 115...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Step 7 (replace completely) ---\n",
    "query = \"\"\"\n",
    "WITH agg AS (\n",
    "  SELECT\n",
    "    p.patient_id,\n",
    "    p.first_name, p.last_name, p.gender, p.age, p.race, p.ethnicity,\n",
    "    p.sdoh_risk_score,\n",
    "    CASE\n",
    "      WHEN p.sdoh_risk_score >= 0.70 THEN 'HIGH'\n",
    "      WHEN p.sdoh_risk_score >= 0.40 THEN 'MEDIUM'\n",
    "      ELSE 'LOW'\n",
    "    END AS sdoh_bucket,\n",
    "    COALESCE(p.insurance, 'Unknown') AS insurance,\n",
    "    COALESCE(p.smoking_status, 'Unknown') AS smoking_status,\n",
    "    COALESCE(p.deceased, FALSE) AS deceased,\n",
    "    NULLIF(p.death_date, '') AS death_date_raw,\n",
    "    COUNT(a.allergy_id) AS allergy_count,\n",
    "    MAX(CASE WHEN LOWER(COALESCE(a.severity,'')) IN ('severe','high','life-threatening') THEN 1 ELSE 0 END) AS any_severe_allergy,\n",
    "    STRING_AGG(a.substance || ' (' || COALESCE(a.severity,'unknown') || ')', '; ' ORDER BY a.substance) AS allergy_list\n",
    "  FROM patients p\n",
    "  LEFT JOIN allergies a ON p.patient_id = a.patient_id\n",
    "  GROUP BY p.patient_id, p.first_name, p.last_name, p.gender, p.age, p.race, p.ethnicity,\n",
    "           p.sdoh_risk_score, insurance, smoking_status, deceased, p.death_date\n",
    ")\n",
    "SELECT\n",
    "  patient_id,\n",
    "  CONCAT(\n",
    "    'Patient: ', first_name, ' ', last_name, '. ',\n",
    "    'Gender: ', COALESCE(gender,'unknown'), '; Age: ', COALESCE(age::text,'unknown'), '. ',\n",
    "    'Race: ', COALESCE(race,'unspecified'), '; Ethnicity: ', COALESCE(ethnicity,'unspecified'), '. ',\n",
    "    'SDOH: ', sdoh_bucket, ' (', COALESCE(sdoh_risk_score::text,'n/a'), '). ',\n",
    "    'Insurance: ', insurance, '; Smoking: ', smoking_status, '. ',\n",
    "    'Deceased: ', CASE WHEN deceased THEN 'yes' ELSE 'no' END,\n",
    "    CASE WHEN deceased AND death_date_raw IS NOT NULL THEN CONCAT(' (death_date=', death_date_raw, ')') ELSE '' END, '. ',\n",
    "    'Allergies: ', COALESCE(allergy_list,'none'), '. ',\n",
    "    'Allergy_count: ', allergy_count::text, '; Any_severe_allergy: ', any_severe_allergy::text, '.'\n",
    "  ) AS context_text\n",
    "FROM agg;\n",
    "\"\"\"\n",
    "\n",
    "df_context = pd.read_sql(query, conn)\n",
    "print(f\"‚úÖ Created {len(df_context)} patient context records with labeled facts\")\n",
    "df_context.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80907c20",
   "metadata": {},
   "source": [
    "# 8a. Configure embedding backend (Ollama or LLM API)\n",
    "\n",
    "Set `EMBEDDING_BACKEND` to `\"ollama\"` for the local Ollama workflow or `\"llm_api\"` to call an OpenAPI-compatible embedding service. When using the hosted path, export `OPENAI_API_KEY` (and optionally `OPENAI_BASE_URL`, `OPENAI_EMBED_MODEL`, `OPENAI_ORG`) before running the cell. Use `EMBEDDING_DIM` if the remote model emits vectors larger/smaller than the pgvector column, and set `SKIP_EMBEDDING_SMOKETEST=1` to bypass the quick connectivity check.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4963a5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Embedding backend: llm_api\n",
      " - API base URL: https://api.openai.com/v1/embeddings\n",
      " - Remote model: text-embedding-3-small\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_BACKEND = os.getenv('EMBEDDING_BACKEND', 'ollama').strip().lower()\n",
    "if EMBEDDING_BACKEND not in {'ollama', 'llm_api'}:\n",
    "    raise ValueError(f'Unsupported EMBEDDING_BACKEND: {EMBEDDING_BACKEND}')\n",
    "\n",
    "OLLAMA_EMBED_MODEL = os.getenv('OLLAMA_EMBED_MODEL', 'phi4-mini')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "OPENAI_BASE_URL = os.getenv('OPENAI_BASE_URL', 'https://api.openai.com/v1').rstrip('/')\n",
    "OPENAI_EMBED_MODEL = os.getenv('OPENAI_EMBED_MODEL', 'text-embedding-3-small')\n",
    "OPENAI_ORG = os.getenv('OPENAI_ORG')\n",
    "EMBEDDING_TIMEOUT = int(os.getenv('EMBEDDING_TIMEOUT', '30'))\n",
    "EMBEDDING_DIM_OVERRIDE = os.getenv('EMBEDDING_DIM')\n",
    "EMBEDDING_DIM_OVERRIDE = int(EMBEDDING_DIM_OVERRIDE) if EMBEDDING_DIM_OVERRIDE else None\n",
    "SKIP_EMBEDDING_SMOKETEST = os.getenv('SKIP_EMBEDDING_SMOKETEST', '0') == '1'\n",
    "\n",
    "if EMBEDDING_BACKEND == 'llm_api' and not OPENAI_API_KEY:\n",
    "    raise RuntimeError('Set OPENAI_API_KEY before selecting the llm_api backend.')\n",
    "\n",
    "print(f'üì¶ Embedding backend: {EMBEDDING_BACKEND}')\n",
    "if EMBEDDING_BACKEND == 'ollama':\n",
    "    print(f' - Ollama model: {OLLAMA_EMBED_MODEL}')\n",
    "else:\n",
    "    print(f' - API base URL: {OPENAI_BASE_URL}/embeddings')\n",
    "    print(f' - Remote model: {OPENAI_EMBED_MODEL}')\n",
    "    if EMBEDDING_DIM_OVERRIDE:\n",
    "        print(f' - Expected vector length override: {EMBEDDING_DIM_OVERRIDE}')\n",
    "if SKIP_EMBEDDING_SMOKETEST:\n",
    "    print('‚è≠Ô∏è Skipping embedding smoke test will defer dimension discovery to Step 9.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42df8cf5-8efa-4796-9a51-002f27a0c500",
   "metadata": {},
   "source": [
    "# 8b. Embedding helper functions\n",
    "\n",
    "Dispatch requests to the selected backend, normalize outputs, and guard against vector length mismatches before storing embeddings in Postgres.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c39a2538-b88e-465b-9bdf-39ae7e024bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ llm_api embedding length: 1536\n"
     ]
    }
   ],
   "source": [
    "EXPECTED_EMBEDDING_DIM = EMBEDDING_DIM_OVERRIDE\n",
    "\n",
    "\n",
    "def _embed_with_ollama(text, model):\n",
    "    payload = {'model': model, 'prompt': text}\n",
    "    response = requests.post('http://localhost:11434/api/embeddings', json=payload, timeout=EMBEDDING_TIMEOUT)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    if 'embedding' not in data:\n",
    "        raise ValueError(f'Unexpected Ollama response: {data}')\n",
    "    return data['embedding']\n",
    "\n",
    "\n",
    "def _embed_with_llm_api(text, model):\n",
    "    headers = {'Authorization': f'Bearer {OPENAI_API_KEY}'}\n",
    "    if OPENAI_ORG:\n",
    "        headers['OpenAI-Organization'] = OPENAI_ORG\n",
    "    payload = {'model': model, 'input': text}\n",
    "    response = requests.post(f'{OPENAI_BASE_URL}/embeddings', headers=headers, json=payload, timeout=EMBEDDING_TIMEOUT)\n",
    "    response.raise_for_status()\n",
    "    body = response.json()\n",
    "    try:\n",
    "        return body['data'][0]['embedding']\n",
    "    except (KeyError, IndexError) as exc:\n",
    "        raise ValueError(f'Unexpected LLM API response: {body}') from exc\n",
    "\n",
    "\n",
    "def get_embedding(text, *, model=None):\n",
    "    global EXPECTED_EMBEDDING_DIM\n",
    "    if not text:\n",
    "        raise ValueError('Text to embed must be non-empty.')\n",
    "    if EMBEDDING_BACKEND == 'ollama':\n",
    "        vector = _embed_with_ollama(text, model or OLLAMA_EMBED_MODEL)\n",
    "    else:\n",
    "        vector = _embed_with_llm_api(text, model or OPENAI_EMBED_MODEL)\n",
    "    length = len(vector)\n",
    "    if EXPECTED_EMBEDDING_DIM is None:\n",
    "        EXPECTED_EMBEDDING_DIM = length\n",
    "    elif length != EXPECTED_EMBEDDING_DIM:\n",
    "        raise ValueError(f'Embedding length mismatch: expected {EXPECTED_EMBEDDING_DIM}, got {length}')\n",
    "    return vector\n",
    "\n",
    "\n",
    "if not SKIP_EMBEDDING_SMOKETEST:\n",
    "    smoke_vec = get_embedding('test patient embedding')\n",
    "    print(f'‚úÖ {EMBEDDING_BACKEND} embedding length: {len(smoke_vec)}')\n",
    "else:\n",
    "    print('‚ÑπÔ∏è Smoke test deferred; the first embedding call will determine vector length.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946a191e-9457-4dc6-a84a-6ec02e8798ec",
   "metadata": {},
   "source": [
    "# 9. Create and fill patient_embeddings\n",
    "\n",
    "The table uses the discovered embedding dimension (from the smoke test or the first context embedding) so it works with either backend.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75e0d78c-7b09-4bda-9cf8-ea995727dd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Re-embedded 1000 patients with 1536-d vectors via llm_api\n"
     ]
    }
   ],
   "source": [
    "if df_context.empty:\n",
    "    raise ValueError('df_context is empty; run Step 7 before generating embeddings.')\n",
    "\n",
    "cached_first_embedding = None\n",
    "if EXPECTED_EMBEDDING_DIM is None:\n",
    "    cached_first_embedding = get_embedding(df_context.iloc[0].context_text)\n",
    "    vector_length = len(cached_first_embedding)\n",
    "else:\n",
    "    vector_length = EXPECTED_EMBEDDING_DIM\n",
    "\n",
    "cur.execute('DROP TABLE IF EXISTS patient_embeddings;')\n",
    "cur.execute(f\"\"\"\n",
    "CREATE TABLE patient_embeddings (\n",
    "  patient_id TEXT PRIMARY KEY,\n",
    "  context_text TEXT,\n",
    "  embedding VECTOR({vector_length})\n",
    ");\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "\n",
    "for idx, row in enumerate(df_context.itertuples(index=False)):\n",
    "    if idx == 0 and cached_first_embedding is not None:\n",
    "        emb = cached_first_embedding\n",
    "    else:\n",
    "        emb = get_embedding(row.context_text)\n",
    "    cur.execute(\n",
    "        'INSERT INTO patient_embeddings (patient_id, context_text, embedding) VALUES (%s, %s, %s)',\n",
    "        (row.patient_id, row.context_text, emb)\n",
    "    )\n",
    "conn.commit()\n",
    "print(f'‚úÖ Re-embedded {len(df_context)} patients with {vector_length}-d vectors via {EMBEDDING_BACKEND}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074e0d46-3cff-4680-af71-6149e7ba7765",
   "metadata": {},
   "source": [
    "# 10. Train UMAP reducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3447fb72-ef70-446c-acb7-c4ae39511c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/anaconda3/envs/lab/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/kevin/anaconda3/envs/lab/lib/python3.12/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ UMAP trained on 1000 patient embeddings.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import umap\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "\n",
    "cur.execute(\"SELECT patient_id, embedding FROM patient_embeddings;\")\n",
    "rows = cur.fetchall()\n",
    "\n",
    "embeddings = np.vstack([\n",
    "    np.array(ast.literal_eval(r[1]), dtype=np.float32) if isinstance(r[1], str) else np.array(r[1], dtype=np.float32)\n",
    "    for r in rows\n",
    "])\n",
    "patient_ids = [r[0] for r in rows]\n",
    "\n",
    "reducer = umap.UMAP(n_neighbors=5, min_dist=0.3, metric=\"cosine\", random_state=42)\n",
    "embedding_2d = reducer.fit_transform(embeddings)\n",
    "\n",
    "print(f\"‚úÖ UMAP trained on {len(patient_ids)} patient embeddings.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b6b8da-a0c2-4776-a279-78102a53f2d1",
   "metadata": {},
   "source": [
    "# 11. Semantic search query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf224d0-8f65-4d23-af87-916d4f22f6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = 'patients allergic to penicillin with high sdoh risk'\n",
    "query_emb = get_embedding(query_text)\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT p.patient_id,\n",
    "       p.context_text,\n",
    "       1 - (p.embedding <=> %s::vector) AS similarity\n",
    "FROM patient_embeddings p\n",
    "ORDER BY similarity DESC\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "\n",
    "cur.execute(sql, (query_emb,))\n",
    "results = cur.fetchall()\n",
    "\n",
    "pd.DataFrame(results, columns=['patient_id', 'context_text', 'similarity'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b34be92-714f-4e31-8b8a-75251b4c68dc",
   "metadata": {},
   "source": [
    "# 12. Visualization (Matplotlib + Plotly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029cad23-2f0a-4c8f-8065-ca728f536393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 12: Visualize patient embeddings with optional query overlay ---\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(embedding_2d[:,0], embedding_2d[:,1], s=40, alpha=0.8)\n",
    "plt.title(\"Patient Embedding Clusters (œÜ4-mini)\")\n",
    "plt.xlabel(\"UMAP-1\")\n",
    "plt.ylabel(\"UMAP-2\")\n",
    "plt.show()\n",
    "\n",
    "# Optional: Interactive hover view\n",
    "df_plot = pd.DataFrame({\n",
    "    \"x\": embedding_2d[:,0],\n",
    "    \"y\": embedding_2d[:,1],\n",
    "    \"patient_id\": patient_ids,\n",
    "    \"context_text\": [r[1] for r in rows]\n",
    "})\n",
    "\n",
    "fig = px.scatter(\n",
    "    df_plot,\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    hover_data={\"patient_id\": True, \"context_text\": True},\n",
    "    title=\"Interactive Semantic Map of Patients\",\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "fig.update_traces(marker=dict(size=10, opacity=0.8))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65658a80-27a9-45a7-88aa-6c74f20df8da",
   "metadata": {},
   "source": [
    "# 12. Add NLP Semantic Search for Patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6907f219-9182-46ac-b8bf-8e9a4f930050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "def embed_query_vector(text):\n",
    "    return np.array(get_embedding(text), dtype=np.float32)\n",
    "\n",
    "\n",
    "def semantic_search_fused(query_text, top_k=5):\n",
    "    # Parse rule-based filters\n",
    "    filters = parse_filters(query_text)\n",
    "    candidate_ids = candidate_ids_from_filters(filters)\n",
    "\n",
    "    if not candidate_ids:\n",
    "        cur.execute('SELECT patient_id, embedding FROM patient_embeddings;')\n",
    "    else:\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            SELECT patient_id, embedding\n",
    "            FROM patient_embeddings\n",
    "            WHERE patient_id = ANY(%s);\n",
    "        \"\"\",\n",
    "            (candidate_ids,)\n",
    "        )\n",
    "    rows = cur.fetchall()\n",
    "\n",
    "    if not rows:\n",
    "        print('No candidates match the prefilters.')\n",
    "        return None, pd.DataFrame()\n",
    "\n",
    "    q_emb = embed_query_vector(query_text).reshape(1, -1)\n",
    "\n",
    "    ids, mats = [], []\n",
    "    for pid, emb in rows:\n",
    "        if isinstance(emb, str):\n",
    "            emb = json.loads(emb)\n",
    "        mats.append(np.array(emb, dtype=np.float32))\n",
    "        ids.append(pid)\n",
    "    E = np.vstack(mats)\n",
    "\n",
    "    sims = cosine_similarity(q_emb, E)[0]\n",
    "    order = np.argsort(-sims)[:top_k]\n",
    "    top = [(ids[i], float(sims[i])) for i in order]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for pid, score in top:\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            SELECT first_name, last_name, gender, age, race, ethnicity,\n",
    "                   sdoh_risk_score, insurance, smoking_status, deceased, death_date\n",
    "            FROM patients WHERE patient_id = %s;\n",
    "        \"\"\",\n",
    "            (pid,)\n",
    "        )\n",
    "        p = cur.fetchone()\n",
    "\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            SELECT substance, severity, reaction\n",
    "            FROM allergies WHERE patient_id = %s\n",
    "            ORDER BY severity DESC NULLS LAST, substance\n",
    "            LIMIT 3;\n",
    "        \"\"\",\n",
    "            (pid,)\n",
    "        )\n",
    "        alls = cur.fetchall()\n",
    "        allergy_summary = '; '.join([f\"{a[0]} ({a[1] or 'unknown'})\" for a in alls]) if alls else 'None'\n",
    "\n",
    "        sdoh_bucket = 'HIGH' if (p[6] and p[6] >= 0.70) else ('MEDIUM' if (p[6] and p[6] >= 0.40) else 'LOW')\n",
    "\n",
    "        # --- EXPLANATION SECTION ---\n",
    "        explanations = []\n",
    "        if filters['gender']:\n",
    "            explanations.append(f\"gender={p[2]} {'‚úÖ' if p[2] and p[2].lower()==filters['gender'] else '‚ùå'}\")\n",
    "        if filters['sdoh_bucket']:\n",
    "            explanations.append(f\"SDOH={sdoh_bucket} {'‚úÖ' if sdoh_bucket==filters['sdoh_bucket'] else '‚ùå'}\")\n",
    "        if filters['deceased'] is not None:\n",
    "            explanations.append(f\"deceased={p[9]} {'‚úÖ' if bool(p[9])==filters['deceased'] else '‚ùå'}\")\n",
    "        if filters['recent_days']:\n",
    "            explanations.append(f\"recent_check={filters['recent_days']}d window\")\n",
    "        explanation = '; '.join(explanations) if explanations else 'No explicit filter matches'\n",
    "\n",
    "        results.append({\n",
    "            'Patient ID': pid,\n",
    "            'Name': f\"{p[0]} {p[1]}\",\n",
    "            'Gender': p[2],\n",
    "            'Age': p[3],\n",
    "            'SDOH': f\"{sdoh_bucket} ({p[6]})\",\n",
    "            'Insurance': p[7],\n",
    "            'Smoking': p[8],\n",
    "            'Deceased': p[9],\n",
    "            'Death Date': p[10],\n",
    "            'Allergies (sample)': allergy_summary,\n",
    "            'Similarity': round(score, 3),\n",
    "            'Filter Match Summary': explanation\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "\n",
    "    print(f\"\\nüîé Query: {query_text}\")\n",
    "    print(tabulate(df, headers='keys', tablefmt='fancy_grid', showindex=False))\n",
    "\n",
    "    return q_emb, df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737e9142-18af-49ac-8171-2701022ba9ea",
   "metadata": {},
   "source": [
    "# 13. Filtering + fused semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974ddb12-527f-46aa-b517-d20e83bca2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def parse_filters(query_text):\n",
    "    q = query_text.lower()\n",
    "\n",
    "    filters = {\n",
    "        \"gender\": None,\n",
    "        \"sdoh_bucket\": None,\n",
    "        \"deceased\": None,\n",
    "        \"recent_days\": None\n",
    "    }\n",
    "\n",
    "    if \"female\" in q: filters[\"gender\"] = \"female\"\n",
    "    if \"male\" in q and \"female\" not in q: filters[\"gender\"] = \"male\"\n",
    "\n",
    "    if \"high sdoh\" in q or \"high social risk\" in q:   filters[\"sdoh_bucket\"] = \"HIGH\"\n",
    "    elif \"low sdoh\" in q or \"low social risk\" in q:   filters[\"sdoh_bucket\"] = \"LOW\"\n",
    "    elif \"medium sdoh\" in q or \"medium social risk\" in q: filters[\"sdoh_bucket\"] = \"MEDIUM\"\n",
    "\n",
    "    if \"deceased\" in q or \"death\" in q:\n",
    "        filters[\"deceased\"] = True\n",
    "        if \"recent\" in q or \"recently\" in q:\n",
    "            filters[\"recent_days\"] = 180  # tweak as needed\n",
    "\n",
    "    return filters\n",
    "def candidate_ids_from_filters(filters):\n",
    "    clauses, params = [], []\n",
    "\n",
    "    if filters[\"gender\"]:\n",
    "        clauses.append(\"LOWER(gender) = %s\")\n",
    "        params.append(filters[\"gender\"])\n",
    "\n",
    "    if filters[\"sdoh_bucket\"]:\n",
    "        clauses.append(\"\"\"\n",
    "        CASE\n",
    "          WHEN sdoh_risk_score >= 0.70 THEN 'HIGH'\n",
    "          WHEN sdoh_risk_score >= 0.40 THEN 'MEDIUM'\n",
    "          ELSE 'LOW'\n",
    "        END = %s\n",
    "        \"\"\")\n",
    "        params.append(filters[\"sdoh_bucket\"])\n",
    "\n",
    "    if filters[\"deceased\"] is True and filters[\"recent_days\"]:\n",
    "        days = int(filters[\"recent_days\"])\n",
    "        clauses.append(f\"\"\"\n",
    "          COALESCE(deceased, FALSE) = TRUE\n",
    "          AND NULLIF(death_date,'') IS NOT NULL\n",
    "          AND death_date ~ '^[0-9]{{4}}-[0-9]{{2}}-[0-9]{{2}}$'\n",
    "          AND TO_DATE(death_date, 'YYYY-MM-DD') >= (CURRENT_DATE - INTERVAL '{days} days')\n",
    "        \"\"\")\n",
    "    \n",
    "    elif filters[\"deceased\"] is True:\n",
    "        clauses.append(\"COALESCE(deceased, FALSE) = TRUE\")\n",
    "\n",
    "    where_sql = (\"WHERE \" + \" AND \".join(clauses)) if clauses else \"\"\n",
    "    sql = f\"SELECT patient_id FROM patients {where_sql};\"\n",
    "    cur.execute(sql, params)\n",
    "    return [r[0] for r in cur.fetchall()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449cb275-e536-4938-8186-60da88ea0469",
   "metadata": {},
   "source": [
    "# Run queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e36b93-81ed-47bc-b864-87dd9ac610f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_emb, df_results = semantic_search_fused(\"patients experiencing headaches\", top_k=5)\n",
    "\n",
    "semantic_search_fused(\"recently deceased patient with respiratory reaction and low income\", top_k=5)\n",
    "\n",
    "semantic_search_fused(\"female patient deceased recently with severe drug allergy\", top_k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62359aa-fa31-477f-8615-d1eb3d755019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 13: Project query embedding into same UMAP ---\n",
    "q_emb = np.array(q_emb, dtype=np.float32).reshape(1, -1)\n",
    "q_emb_2d = reducer.transform(q_emb)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(embedding_2d[:,0], embedding_2d[:,1], alpha=0.3, label='Patients')\n",
    "plt.scatter(q_emb_2d[:,0], q_emb_2d[:,1], color='red', s=120, label='Query')\n",
    "plt.legend()\n",
    "plt.title(\"Query Position in Patient Semantic Space\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12833126-1b7b-4dcd-adc6-da6dbbb00320",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
